import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from llama import Llama

# Carregar o conjunto de dados
diretorio_treino_saudavel = "dataset/treino_saudavel"
diretorio_treino_doente = "dataset/treino_doente"

treino_saudavel = ImageDataGenerator(rescale=1./255).flow_from_directory(
    diretorio=diretorio_treino_saudavel,
    target_size=(128, 128),  # Reduzir o tamanho da imagem para otimização móvel
    batch_size=16,  # Diminuir o tamanho do lote para otimização de memória
    class_mode='binary'
)

treino_doente = ImageDataGenerator(rescale=1./255).flow_from_directory(
    diretorio=diretorio_treino_doente,
    target_size=(128, 128),  # Reduzir o tamanho da imagem para otimização móvel
    batch_size=16,  # Diminuir o tamanho do lote para otimização de memória
    class_mode='binary'
)

treino = tf.data.experimental.concatenate([treino_saudavel, treino_doente])

# Criar um modelo neural compacto
modelo = Sequential()
modelo.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))
modelo.add(MaxPooling2D((2, 2)))
modelo.add(Conv2D(64, (3, 3), activation='relu'))
modelo.add(MaxPooling2D((2, 2)))
modelo.add(Flatten())
modelo.add(Dense(64, activation='relu'))
modelo.add(Dense(1, activation='sigmoid'))

# Treinar a IA Green Mind
modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
modelo.fit(treino, epochs=5, steps_per_epoch=len(treino_saudavel) // 16 + len(treino_doente) // 16)

# Fazer predições com a IA Green Mind
nova_imagem = tf.keras.preprocessing.image.load_img("nova_imagem.jpg", target_size=(128, 128))
nova_imagem = tf.keras.preprocessing.image.img_to_array(nova_imagem)
nova_imagem = np.expand_dims(nova_imagem, axis=0)

prediçao = modelo.predict(nova_imagem)

if prediçao[0] > 0.5:
    print("Planta doente")
else:
    print("Planta saudável")

